{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85169f4",
   "metadata": {},
   "source": [
    "[*Using Multimodal inputs with GPT4o for Image Recognition on SAP AI Core*](https://developers.sap.com/tutorials/ai-core-gpt4o-consumption.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a7dfa5",
   "metadata": {},
   "source": [
    "## Using Multimodal inputs with GPT4o for Image Recognition on SAP AI Core\n",
    "Multimodality refers to the ability of a model to process and interpret different types of inputs, such as text, images, audio, or video. In the context of GPT-4o on SAP AI Core, multimodal input allows the model to understand and generate responses that incorporate both text and visual data. This enhances the modelâ€™s ability to perform complex tasks, such as scene detection, object recognition, and image analysis, by combining the strengths of both language processing and image recognition.In this tutorial, we will demonstrate these capabilities with the help of GPT-4o, with a sample input and output, which can be replicated in future for various use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec630573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource group is set to: default\n"
     ]
    }
   ],
   "source": [
    "from config import init_env\n",
    "from config import variables\n",
    "import importlib\n",
    "variables = importlib.reload(variables)\n",
    "\n",
    "# TODO: You need to specify which model you want to use. In this case we are directing our prompt\n",
    "# to the openAI API directly so you need to pick one of the GPT models. Make sure the model is actually deployed\n",
    "# in genAI Hub. You might also want to chose a model that can also process images here already. \n",
    "# E.g. 'gpt-4.1-mini'\n",
    "MODEL_NAME = 'gpt-4o'\n",
    "\n",
    "# Do not modify the `assert` line below\n",
    "assert MODEL_NAME!='', \"\"\"You should change the variable `MODEL_NAME` with the name of your deployed model (like 'gpt-4o-mini') first!\"\"\"\n",
    "\n",
    "init_env.set_environment_variables()\n",
    "# Do not modify the `assert` line below \n",
    "assert variables.RESOURCE_GROUP!='', \"\"\"You should change the value assigned to the `RESOURCE_GROUP` in the `variables.py` file to your own resource group first!\"\"\"\n",
    "\n",
    "print(f\"Resource group is set to: {variables.RESOURCE_GROUP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eedd4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe75beb",
   "metadata": {},
   "source": [
    "### Scene Detection\n",
    "In this step, we demonstrate how to use GPT-4o to describe a scene depicted in an image. By providing both text and an image URL as input, the model is able to generate a descriptive response that captures the key elements of the scene. This capability is particularly useful for applications like automated content tagging, visual storytelling, or enhancing user experience in multimedia platforms and more.\n",
    "\n",
    "Follow the further steps to replicate scene detection using GPT-4o.\n",
    "\n",
    "To utilize the GPT-4o model, which supports both text and image inputs, use the code below. This example demonstrates how to create a prompt with an image URL and a text query, enabling the model to process and provide a response based on both visual and textual information.\n",
    "\n",
    "Note: You can replace the image URL with any image of your choice and modify the text prompt to ask the model any question about that image based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d06c3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "def encode_image_from_url(image_url):\n",
    "    \"\"\"Download and encode image to base64 format from URL.\"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        return base64.b64encode(response.content).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccfc9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_prompt(image_url, text_prompt):\n",
    "    \"\"\"Create a prompt message for the model with the image data.\"\"\"\n",
    "    # Encode image URL to base64 format\n",
    "    image_base64 = encode_image_from_url(image_url)\n",
    "    \n",
    "    # Create messages including both text and image input\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url  # Use the direct image URL\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85d7b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(model_name, messages):\n",
    "    \"\"\"Send messages to the model and return the response.\"\"\"\n",
    "    kwargs = dict(model_name=model_name, messages=messages)\n",
    "    response = chat.completions.create(**kwargs)\n",
    "    return response.to_dict()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a7b5f",
   "metadata": {},
   "source": [
    "By following this example, you can easily integrate image-based inputs with the GPT-4o model and leverage its ability to understand and generate responses based on both visual and text content. For additional guidance, refer to the screenshot below.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/sceneDetection.jpg\" width=\"30%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10608845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A blue bottle, black headphones, and a power outlet with an on switch are placed on a white table against a maroon and beige partition.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/sceneDetection.jpg\"\n",
    "text_prompt = \"Describe the image in one line.\"  # Prompt asking for the description\n",
    "model_name = \"gpt-4o\"  # Replace with the model that supports image input\n",
    "\n",
    "# Create prompt with image and text\n",
    "messages = create_image_prompt(image_url, text_prompt)\n",
    "\n",
    "# Get response from model\n",
    "response = get_response_from_model(model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2681c3a",
   "metadata": {},
   "source": [
    "### Object Detection\n",
    "This step focuses on identifying and labeling objects within an image. The multimodal input allows GPT-4o to analyze the visual data and generate a list of objects detected in the scene. Object detection is crucial for tasks such as inventory management, autonomous driving, and augmented reality applications and such.\n",
    "\n",
    "Follow the further steps to replicate object detection using GPT-4o.\n",
    "\n",
    "To utilize the GPT-4o model, which supports both text and image inputs, use the code below. This example demonstrates how to create a prompt with an image URL and a text query, enabling the model to process and provide a response based on both visual and textual information.\n",
    "\n",
    "Note: You can replace the image URL with any image of your choice and modify the text prompt to ask the model any question about that image based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c0184e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "def encode_image_from_url(image_url):\n",
    "    \"\"\"Download and encode image to base64 format from URL.\"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        return base64.b64encode(response.content).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd3f1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_prompt(image_url, text_prompt):\n",
    "    \"\"\"Create a prompt message for the model with the image data.\"\"\"\n",
    "    # Encode image URL to base64 format\n",
    "    image_base64 = encode_image_from_url(image_url)\n",
    "        # Create messages including both text and image input\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url  # Use the direct image URL\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c021820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(model_name, messages):\n",
    "    \"\"\"Send messages to the model and return the response.\"\"\"\n",
    "    kwargs = dict(model_name=model_name, messages=messages)\n",
    "    response = chat.completions.create(**kwargs)\n",
    "    return response.to_dict()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0335c5e",
   "metadata": {},
   "source": [
    "By following this example, you can easily integrate image-based inputs with the GPT-4o model and leverage its ability to understand and generate responses based on both visual and text content. For additional guidance, refer to the screenshot below.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/objectDetection.jpg\" width=\"30%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba60e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bottle color is blue, and there is one bottle in the image.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/objectDetection.jpg\"\n",
    "text_prompt = \"give me the bottle color and its count.\"  # Prompt asking for the description\n",
    "model_name = \"gpt-4o\"  # Replace with the model that supports image input\n",
    "\n",
    "# Create prompt with image and text\n",
    "messages = create_image_prompt(image_url, text_prompt)\n",
    "\n",
    "# Get response from model\n",
    "response = get_response_from_model(model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f5bcd",
   "metadata": {},
   "source": [
    "### Graph Analysis\n",
    "Here, the tutorial demonstrates how GPT-4o can be used to interpret and analyze data presented in graphical form. By combining text and image input, the model can extract meaningful insights from charts, graphs, and other visual data representations. This step is valuable for data analysis, reporting, and decision-making processes.\n",
    "\n",
    "Follow the further steps to replicate graph analysis using GPT-4o.\n",
    "\n",
    "To utilize the GPT-4o model, which supports both text and image inputs, use the code below. This example demonstrates how to create a prompt with an image URL and a text query, enabling the model to process and provide a response based on both visual and textual information.\n",
    "\n",
    "Note: You can replace the image URL with any image of your choice and modify the text prompt to ask the model any question about that image based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65f7cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "def encode_image_from_url(image_url):\n",
    "    \"\"\"Download and encode image to base64 format from URL.\"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        return base64.b64encode(response.content).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d4866bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_prompt(image_url, text_prompt):\n",
    "    \"\"\"Create a prompt message for the model with the image data.\"\"\"\n",
    "    # Encode image URL to base64 format\n",
    "    image_base64 = encode_image_from_url(image_url)\n",
    "    \n",
    "    # Create messages including both text and image input\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url  # Use the direct image URL\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31b4ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(model_name, messages):\n",
    "    \"\"\"Send messages to the model and return the response.\"\"\"\n",
    "    kwargs = dict(model_name=model_name, messages=messages)\n",
    "    response = chat.completions.create(**kwargs)\n",
    "    return response.to_dict()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020aa72",
   "metadata": {},
   "source": [
    "By following this example, you can easily integrate image-based inputs with the GPT-4o model and leverage its ability to understand and generate responses based on both visual and text content. For additional guidance, refer to the screenshot below.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/graph.jpg\" width=\"30%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "966db2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph depicts the performance of the Dow Jones Industrial Average (DJIA) from around 2011 to 2023. The DJIA is a stock market index that represents 30 large, publicly-owned companies based in the United States. The graph shows the ups and downs of the index over this period, indicating trends, growth, and fluctuations in the market. The sharp drop around 2020 corresponds to the market impact of the COVID-19 pandemic, followed by a recovery and continued growth.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/graph.jpg\"\n",
    "text_prompt = \"what is this graph about\"  # Prompt asking for the description\n",
    "model_name = \"gpt-4o\"  # Replace with the model that supports image input\n",
    "\n",
    "# Create prompt with image and text\n",
    "messages = create_image_prompt(image_url, text_prompt)\n",
    "# Get response from model\n",
    "response = get_response_from_model(model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1fa27a",
   "metadata": {},
   "source": [
    "### Math\n",
    "In this step, we explore how GPT-4o handles mathematical problems that involve both textual descriptions and visual data. The model can solve equations, interpret mathematical expressions in images, and provide detailed explanations of its reasoning. This capability is useful in educational tools, scientific research, and engineering applications.\n",
    "\n",
    "Follow the further steps to replicate mathematical operations using GPT-4o.\n",
    "\n",
    "To utilize the GPT-4o model, which supports both text and image inputs, use the code below. This example demonstrates how to create a prompt with an image URL and a text query, enabling the model to process and provide a response based on both visual and textual information.\n",
    "\n",
    "Note: You can replace the image URL with any image of your choice and modify the text prompt to ask the model any question about that image based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "350484f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "def encode_image_from_url(image_url):\n",
    "    \"\"\"Download and encode image to base64 format from URL.\"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        return base64.b64encode(response.content).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ad66a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_prompt(image_url, text_prompt):\n",
    "    \"\"\"Create a prompt message for the model with the image data.\"\"\"\n",
    "    # Encode image URL to base64 format\n",
    "    image_base64 = encode_image_from_url(image_url)\n",
    "    \n",
    "    # Create messages including both text and image input\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url  # Use the direct image URL\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a478ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(model_name, messages):\n",
    "    \"\"\"Send messages to the model and return the response.\"\"\"\n",
    "    kwargs = dict(model_name=model_name, messages=messages)\n",
    "    response = chat.completions.create(**kwargs)\n",
    "    return response.to_dict()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64512899",
   "metadata": {},
   "source": [
    "By following this example, you can easily integrate image-based inputs with the GPT-4o model and leverage its ability to understand and generate responses based on both visual and text content. For additional guidance, refer to the screenshot below.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/math.jpg\" width=\"20%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d06f96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the equation \\((2x - 10)/2 = 3(x - 1)\\), follow these steps:\n",
      "\n",
      "1. Multiply both sides by 2 to eliminate the fraction:\n",
      "   \\[\n",
      "   2x - 10 = 6(x - 1)\n",
      "   \\]\n",
      "\n",
      "2. Distribute the 6 on the right-hand side:\n",
      "   \\[\n",
      "   2x - 10 = 6x - 6\n",
      "   \\]\n",
      "\n",
      "3. Rearrange the equation to bring all terms involving \\(x\\) on one side and constant terms on the other side. Subtract \\(2x\\) from both sides:\n",
      "   \\[\n",
      "   -10 = 4x - 6\n",
      "   \\]\n",
      "\n",
      "4. Add 6 to both sides to isolate the term with \\(x\\):\n",
      "   \\[\n",
      "   -4 = 4x\n",
      "   \\]\n",
      "\n",
      "5. Divide both sides by 4 to solve for \\(x\\):\n",
      "   \\[\n",
      "   x = -1\n",
      "   \\]\n",
      "\n",
      "Thus, the solution is \\(x = -1\\).\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/math.jpg\"\n",
    "text_prompt = \"find x\"  # Prompt asking for the description\n",
    "model_name = \"gpt-4o\"  # Replace with the model that supports image input\n",
    "\n",
    "# Create prompt with image and text\n",
    "messages = create_image_prompt(image_url, text_prompt)\n",
    "\n",
    "# Get response from model\n",
    "response = get_response_from_model(model_name, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4419e4",
   "metadata": {},
   "source": [
    "### Image to Text\n",
    "The final step focuses on converting visual information into text. By providing an image as input, GPT-4o generates a textual description or transcription of the content. This step is particularly beneficial for accessibility tools, content creation, and archiving visual data.\n",
    "\n",
    "Follow the further steps to replicate Optical Character Recognition (OCR) using GPT-4o.\n",
    "\n",
    "To utilize the GPT-4o model, which supports both text and image inputs, use the code below. This example demonstrates how to create a prompt with an image URL and a text query, enabling the model to process and provide a response based on both visual and textual information.\n",
    "\n",
    "Note: You can replace the image URL with any image of your choice and modify the text prompt to ask the model any question about that image based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c90f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "def encode_image_from_url(image_url):\n",
    "    \"\"\"Download and encode image to base64 format from URL.\"\"\"\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        return base64.b64encode(response.content).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae2cb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_prompt(image_url, text_prompt):\n",
    "    \"\"\"Create a prompt message for the model with the image data.\"\"\"\n",
    "    # Encode image URL to base64 format\n",
    "    image_base64 = encode_image_from_url(image_url)\n",
    "    \n",
    "    # Create messages including both text and image input\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url  # Use the direct image URL\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5dc0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_from_model(model_name, messages):\n",
    "    \"\"\"Send messages to the model and return the response.\"\"\"\n",
    "    kwargs = dict(model_name=model_name, messages=messages)\n",
    "    response = chat.completions.create(**kwargs)\n",
    "    return response.to_dict()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41351a",
   "metadata": {},
   "source": [
    "By following this example, you can easily integrate image-based inputs with the GPT-4o model and leverage its ability to understand and generate responses based on both visual and text content. For additional guidance, refer to the screenshot below.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/handwrittenText.png\" width=\"45%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "855848d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear User,\n",
      "\n",
      "Handwrytten uses robotic handwriting\n",
      "machines that use an actual pen to\n",
      "write your message. The results are\n",
      "virtually indistinguishable from actual\n",
      "handwriting.\n",
      "Try it today!\n",
      "\n",
      "The Robot\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_url = \"https://raw.githubusercontent.com/SAP-samples/ai-core-samples/main/09_BusinessAIWeek/images/handwrittenText.png\"\n",
    "text_prompt = \"extract text\"  # Prompt asking for the description\n",
    "model_name = \"gpt-4o\"  # Replace with the model that supports image input\n",
    "\n",
    "# Create prompt with image and text\n",
    "messages = create_image_prompt(image_url, text_prompt)\n",
    "\n",
    "# Get response from model\n",
    "response = get_response_from_model(model_name, messages)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
